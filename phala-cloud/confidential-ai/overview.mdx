---
description: Run and inference LLMs securely in GPU TEE for confidential AI.
title: Overview
---

<img
  src="/images/confidential-ai/confidential-ai-overview.jpeg"
/>

<Note>
Run AI models with enterprise-grade security without sacrificing performance. Phala Cloud Confidential AI protects your models and data using GPU TEE - hardware-isolated environments that keep your AI workloads private and verifiable.
</Note>

## Why Confidential AI?

Traditional cloud AI deployments expose your models and data to the cloud provider. Confidential AI solves this by running everything inside hardware-protected TEE. Your models stay private, your data stays secure, and you get cryptographic proof that execution happened in a trusted environment.

## Try Confidential AI

<Columns cols={2}>
  <Card
    icon="webhook"
    href="https://cloud.phala.network/dashboard/confidential-ai-api"
    title="Confidential AI API"
    arrow="true"
  >
    **Try LLM inference API now**

    Pre-deployed LLM inference API with OpenAI-compatible interface
  </Card>

  <Card
    icon="workflow"
    href="https://cloud.phala.network/dashboard/confidential-ai-models"
    title="Confidential AI Models"
    arrow="true"
  >
    **Try inference your own AI models**
    <i class="fa-solid fa-hexagon-nodes"></i>
    Deploy and manage AI models in a secure, confidential computing environment
  </Card>

  <Card
    icon="microchip"
    title="Confidential GPU"
    href="https://cloud.phala.network/dashboard/gpu-tee"
    arrow="true"
  >
    **Try to deploy your own models on GPU TEE**

    Rent dedicated GPU TEE servers for custom model deployment
  </Card>
</Columns>

## Quick Tour of Confidential AI

### API and Models

Choose the option that fits your needs:

[Confidential AI API](/phala-cloud/confidential-ai/confidential-model/confidential-ai-api) offers pre-deployed LLMs with OpenAI-compatible APIs for quick integration.

[Confidential AI Models](/phala-cloud/confidential-ai/confidential-model/confidential-ai-models) lets you deploy and manage custom AI models in GPU TEE.

### Confidential GPU

For complete infrastructure control, use [Confidential GPU](/phala-cloud/confidential-ai/confidential-gpu/overview) to deploy custom models. Configure GPU, CPU, RAM, and storage to match your exact workload needs.


### Verify Attestation and Signature
To ensure your workloads run securely in TEE, you can [Verify Attestation](./verify-attestation) to check the TEE hardware, operating system, source code, and distributed root-of-trust attestations. 

Then you can [Verify Signature](./verify-signature) to confirm the integrity of your Confidential AI API requests and responses.

### Benchmark

Our performance [benchmark](/phala-cloud/confidential-ai/benchmark) shows TEE mode on H100/H200 GPUs runs up to 99% efficiency, nearly matching native performance. This means you get confidential computing with minimal performance penalty.

### FAQs

Check [FAQs](/phala-cloud/confidential-ai/faqs) for frequently asked questions about Confidential AI.


## What makes Phala Cloud Confidential AI Different?

<Columns cols={2}>
  <Card
    icon="webhook"
    href="/phala-cloud/confidential-ai/confidential-model/confidential-ai-api"
    title="API and Models"
  >
    Pre-deployed LLM inference API with OpenAI-compatible interface
  </Card>
  <Card
    icon="microchip"
    title="Confidential GPU"
    href="/phala-cloud/confidential-ai/confidential-gpu/overview"
  >
    Rent dedicated GPU TEE servers for custom model deployment
  </Card>
</Columns>

- **Use existing code**: Drop-in replacement for OpenAI APIs
- **Popular models**: DeepSeek, Llama, GPT-OSS, and Qwen models ready to use
- **Verify execution**: Get attestation reports proving your code ran in TEE
- **Pay as you go**: Only pay for what you use
- **Custom models**: Run your own fine-tuned or proprietary models
- **High performance**: H200, H100, and B200 GPUs available
- **Full control**: Configure CPU, RAM, storage, and location
- **Flexible scaling**: 1 or 8 GPUs per server, various commitment options

## Open Source Foundation

Our underlying technology is open source. Check out the [private-ml-sdk](https://github.com/nearai/private-ml-sdk) repository to see how LLMs run securely in GPU TEEs. This project was built by Phala Network with support from NEARAI.

<Frame caption="Open Source Implementation: Private ML SDK">
  <img
    src="/images/confidential-ai/confidential-model/private-ml-sdk-repo.png"
  />
</Frame>
